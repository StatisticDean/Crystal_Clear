{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Listening to existing samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_sample = pd.read_csv('./samples/meta_samples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_sample.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample(meta_sample, genre=None, crap_id=None, learner_name=None, overlapping_windows=None, pipeline=None, n=None, return_sample=False):\n",
    "    if genre is not None:\n",
    "        meta_sample = meta_sample[meta_sample.genre == genre]\n",
    "    if crap_id is not None:\n",
    "        meta_sample = meta_sample[meta_sample.crap_id == crap_id]\n",
    "    if learner_name is not None:\n",
    "        meta_sample = meta_sample[meta_sample.learner_name == learner_name]\n",
    "    if overlapping_windows is not None:\n",
    "        meta_sample = meta_sample[meta_sample.overlapping_windows == overlapping_windows]\n",
    "    if n is not None:\n",
    "        sample_name, crap_id, learner_name, overlapping_window, pipeline, f = meta_sample.iloc[n][['sample_name', 'crap_id', 'learner_name', 'overlapping_window', 'pipeline', 'format']]\n",
    "    else:\n",
    "        sample_name, crap_id, learner_name, overlapping_window, pipeline, f = meta_sample.sample().iloc[0][['sample_name', 'crap_id', 'learner_name', 'overlapping_window', 'pipeline', 'format']]\n",
    "    pipeline == pipeline[0] + 'p'\n",
    "    orig = AudioSegment.from_file(f'./samples/original/{sample_name}.{f}')\n",
    "    crap = AudioSegment.from_file(f'./samples/crappified/{sample_name}_{crap_id}.{f}')\n",
    "    reco = AudioSegment.from_file(f'./samples/reconstructed/{sample_name}_{crap_id}_{pipeline}_{learner_name}_W{int(overlapping_windows)}.{f}')\n",
    "    print(sample_name)\n",
    "    print('Crappified file :')\n",
    "    display(crap)\n",
    "    print('Reconstructed file :')\n",
    "    display(reco)\n",
    "    print('Original file :')\n",
    "    display(orig)\n",
    "    if return_sample:\n",
    "        return crap, reco, orig\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sample(meta_sample, genre = 'Rock', n=2, pipeline='tensor_pipeline', overlapping_windows=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating new samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crystal_clear.upscale import upscale, FeatureLoss\n",
    "from fastai.basic_train import load_learner\n",
    "from crystal_clear.prepare import path_mp3\n",
    "from crystal_clear.tensor_pipeline import TensorImageImageList, TensorImageList\n",
    "from pathlib import Path\n",
    "from fastai.vision import * \n",
    "from fastai import *\n",
    "from tqdm import tqdm as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv('./data/crappified/dataset_1/meta/meta_mp3.csv')\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_list = np.unique(meta.genre)\n",
    "genre_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proc(pipeline, overlapping_windows):\n",
    "    if pipeline == 'tensor_pipeline':\n",
    "        import torch\n",
    "        from crystal_clear.tensor_pipeline import create_tensor_Processor\n",
    "        data_stats = torch.load('./data/crappified/dataset_1/tensor_pipeline/data_stats.pkl')\n",
    "        proc = create_tensor_Processor(data_stats)\n",
    "        if overlapping_windows:\n",
    "            from crystal_clear.tensor_pipeline import create_song_tensor_Processor2\n",
    "            song_proc = create_song_tensor_Processor2()\n",
    "        else:\n",
    "            from crystal_clear.tensor_pipeline import create_song_tensor_Processor\n",
    "            song_proc = create_song_tensor_Processor()\n",
    "    if pipeline == 'image_pipeline':\n",
    "        if overlapping_windows:\n",
    "            from crystal_clear.image_pipeline import Image_proc as proc, Image_song_proc2 as song_proc\n",
    "        else:\n",
    "            from crystal_clear.image_pipeline import Image_proc as proc, Image_song_proc as song_proc\n",
    "    return proc, song_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current = {'pipeline': '', 'overlapping_windows': None, 'learner':None, 'proc':None, 'song_proc':None}\n",
    "name_learner = {'tensor_pipeline': '1a_tensor.pkl', 'image_pipeline': '1b.pkl'}\n",
    "def update_pipeline(pipeline, overlapping_windows):\n",
    "    if current['pipeline'] != pipeline:\n",
    "        current['learner'] = load_learner(f'./data/crappified/dataset_1/{pipeline}/models_export/', name_learner[pipeline])\n",
    "        current['proc'], current['song_proc'] = get_proc(pipeline, overlapping_windows)\n",
    "        current['overlapping_windows'] = overlapping_windows\n",
    "        current['pipeline'] = pipeline\n",
    "        gc.collect()\n",
    "    else:\n",
    "        if current['overlapping_windows'] != overlapping_windows:\n",
    "            current['proc'], current['song_proc'] = get_proc(pipeline, overlapping_windows)\n",
    "            current['overlapping_windows'] = overlapping_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_track_id(genre=None, n=None):\n",
    "    '''\n",
    "    Get the id of a track in the validation set.\n",
    "    If genre is specified, pick a track in the corresponding genre.\n",
    "    If n is specified, get the n-th track corresponding to the arguments,\n",
    "    else pick a random corresponding track'''\n",
    "    meta_valid = meta[meta.subset == 'valid'].reset_index(drop=True)\n",
    "    if genre is not None:\n",
    "        meta_valid = meta_valid[meta_valid.genre == genre].reset_index(drop=True)\n",
    "    if n is not None:\n",
    "        return meta_valid.loc[n, 'track_id']\n",
    "    else:\n",
    "        return meta_valid.track_id.sample().iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect(track_id, pipeline='tensor_pipeline', overlapping_windows=False, display_music=True, show_progress=True):\n",
    "    path_orig = path_mp3(track_id)\n",
    "    path_crap = Path(f'./data/crappified/dataset_1/mp3/{track_id}.mp3')\n",
    "    orig = AudioSegment.from_mp3(path_orig)\n",
    "    crap = AudioSegment.from_mp3(path_crap)\n",
    "    update_pipeline(pipeline, overlapping_windows)\n",
    "    reconstructed = upscale(path_crap, current['proc'], current['song_proc'], current['learner'], show_progress=show_progress)\n",
    "    if display_music:\n",
    "        print('original')\n",
    "        display(orig)\n",
    "        print('crappified')\n",
    "        display(crap)\n",
    "        print('reconstructed')\n",
    "        display(reconstructed)\n",
    "    return orig, crap, reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_id = get_track_id(n=2, genre='Rock')\n",
    "orig, crap, reconstructed = inspect(track_id, overlapping_windows=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sample(sample_name, orig, crap, reconstructed, learner_name, crap_id=1, pipeline='tensor_pipeline', overlapping_windows=False, format='mp3', genre=''):\n",
    "    for name_folder in ['crappified', 'original', 'reconstructed']:\n",
    "        if not os.path.exists(f'./samples/{name_folder}'):\n",
    "            os.makedirs(f'./samples/{name_folder}')\n",
    "    try:\n",
    "        df_meta_samples = pd.read_csv('./samples/meta_samples.csv')\n",
    "        new_meta = df_meta_samples.append({'sample_name':sample_name, 'crap_id':crap_id,\n",
    "                                           'learner_name': learner_name, 'format':format,\n",
    "                                           'genre':genre, 'pipeline': pipeline,\n",
    "                                           'overlapping_windows': overlapping_windows}, ignore_index=True).drop_duplicates()\n",
    "    except:\n",
    "        new_meta = pd.DataFrame({'sample_name':sample_name, 'crap_id':crap_id,\n",
    "                                 'learner_name':learner_name, 'format':format,\n",
    "                                 'genre':genre, 'pipeline': pipeline,\n",
    "                                 'overlapping_windows': overlapping_windows}, index= [0])\n",
    "    new_meta.to_csv('./samples/meta_samples.csv', index=None)\n",
    "    orig.export(f'./samples/original/{sample_name}.{format}', format=format)\n",
    "    crap.export(f'./samples/crappified/{sample_name}_{crap_id}.{format}', format=format)\n",
    "    pipeline = pipeline[0] + 'p'\n",
    "    reconstructed.export(f'./samples/reconstructed/{sample_name}_{crap_id}_{pipeline}_{learner_name}_W{int(overlapping_windows)}.{format}', format=format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pipeline in ['tensor_pipeline', 'image_pipeline']:\n",
    "    for overlapping_windows in [False, True]:\n",
    "        for genre in tqdm(genre_list):\n",
    "            for i in tqdm(range(4)):\n",
    "                track_id = get_track_id(n=i, genre=genre)\n",
    "                orig, crap, reconstructed = inspect(track_id, pipeline=pipeline, overlapping_windows=overlapping_windows, display_music=False, show_progress=False)\n",
    "                learner_name = name_learner[current['pipeline']]\n",
    "                add_sample(f'{track_id}', orig, crap, reconstructed, learner_name=os.path.splitext(learner_name)[0], pipeline=pipeline, overlapping_windows=overlapping_windows, genre=genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:crystal_clear]",
   "language": "python",
   "name": "conda-env-crystal_clear-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
